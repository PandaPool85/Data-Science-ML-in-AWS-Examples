{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Training Job \n",
    "\n",
    "### Please go through this notebook only if you have finished Part 1 to Part 4 of the tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Step 1: Import packages, get IAM role, get the region and set the S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T12:40:59.982838Z",
     "start_time": "2020-04-16T12:40:30.475824Z"
    }
   },
   "outputs": [],
   "source": [
    "#Do not execute this in demo\n",
    "%%sh \n",
    "pwd\n",
    "cd local_test/test_dir/input/data/training/\n",
    "ls -ltr\n",
    "aws s3 cp data_set s3://eu.com.syngenta-datascience-model-training/Preetam.Balijepalli@syngenta.com/keras-sagemaker/train/data/data_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Step 2: Create the algorithm image and push to Amazon ECR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T11:31:57.935924Z",
     "start_time": "2020-04-16T11:31:57.922674Z"
    }
   },
   "outputs": [],
   "source": [
    "#Do not execute this in demo\n",
    "%%sh\n",
    "\n",
    "chmod +x create_container.sh \n",
    "\n",
    "./create_container.sh keras-sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Step 3: Define variables with data location and output location in S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T07:48:37.805085Z",
     "start_time": "2020-04-17T07:48:37.800614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data location - s3://eu.com.syngenta-datascience-model-training/Preetam.Balijepalli@syngenta.com/keras-sagemaker/train/data\n",
      "output location - s3://eu.com.syngenta-datascience-model-training/Preetam.Balijepalli@syngenta.com/keras-sagemaker/output\n"
     ]
    }
   ],
   "source": [
    "schema = 's3:/' \n",
    "bucket = 'eu.com.syngenta-datascience-model-training'\n",
    "\n",
    "user = 'Preetam.Balijepalli@syngenta.com' \n",
    "experiment = 'keras-sagemaker'\n",
    "\n",
    "\n",
    "data_location = f'{schema}/{bucket}/{user}/{ experiment}/train/data'\n",
    "print(\"data location - \" + data_location)\n",
    "\n",
    "output_location = f'{schema}/{bucket}/{user}/{ experiment}/output'\n",
    "print(\"output location - \" + output_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Step 4: Create a SageMaker session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T07:48:42.126969Z",
     "start_time": "2020-04-17T07:48:41.216551Z"
    }
   },
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "\n",
    "sagemaker_session = sage.Session()\n",
    "\n",
    "# this line of code requires iam:GetRole permissions\n",
    "#role = sage.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Step 5: Define variables for account, region and algorithm image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T07:48:44.899676Z",
     "start_time": "2020-04-17T07:48:44.696613Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170605107178\n",
      "eu-central-1\n",
      "170605107178.dkr.ecr.eu-central-1.amazonaws.com/datascience-model-training:gpu\n"
     ]
    }
   ],
   "source": [
    "account = sagemaker_session.boto_session.client('sts').get_caller_identity()['Account'] # aws account \n",
    "region = sagemaker_session.boto_session.region_name # aws server region\n",
    "tag='gpu'\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/datascience-model-training:{}'.format(account, region, tag) # algorithm image path in ECR\n",
    "#keras-sagemaker-train\n",
    "print(account)\n",
    "print(region)\n",
    "print(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Step 6: Define hyperparameters to be passed to your algorithm. \n",
    "In this project we are reading two hyperparameters for training. Use of hyperparameters in optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T07:48:48.515154Z",
     "start_time": "2020-04-17T07:48:48.512390Z"
    }
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\"batch_size\":128, \"epochs\":30}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Step 7: Create the training job using SageMaker Estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T07:48:50.909571Z",
     "start_time": "2020-04-17T07:48:50.905061Z"
    }
   },
   "outputs": [],
   "source": [
    "role = 'arn:aws:iam::170605107178:role/SYN-Datascience-SageMaker-Role'\n",
    "\n",
    "subnets_config = ['subnet-0bdd33f41f946b22a', 'subnet-0c7c8959343746db7']\n",
    "\n",
    "security_groups_config = [ \"sg-1ad4ea70\",\n",
    "              \"sg-99d781f1\",\n",
    "              \"sg-dfa1f7b7\"]\n",
    "\n",
    "# the instance type to be used for training. using 'local' will not trigger a job on SageMaker\n",
    "instance_count = 1\n",
    "instance_type = 'ml.p3.2xlarge'\n",
    "\n",
    "#https://aws.amazon.com/sagemaker/pricing/\n",
    "#https://aws.amazon.com/sagemaker/pricing/instance-types/\n",
    "\n",
    "#ml.p3.2xlarge Accelerated Computing â€“ Current Generation \t8(CPU cores)\t1xV100(GPU)\t61GiB(CPU mem)\t16GiB(Gpu mem)\n",
    "# ml.c5.2xlarge \t  Compute Instances - Current Generation\t $0.543 16GiB RAM 8 cores\n",
    "# ml.m4.xlarge\t   Compute Instances - Standard Generation\t $0.336 16GiB Ram 4 cores\n",
    "\n",
    "\n",
    "classifier = sage.estimator.Estimator(image_name=image, \n",
    "                                      role=role,\n",
    "                                      train_instance_count=instance_count, \n",
    "                                      train_instance_type= instance_type,\n",
    "                                      hyperparameters=hyperparameters,\n",
    "                                      output_path=output_location,\n",
    "                                      subnets=subnets_config, \n",
    "                                      security_group_ids=security_groups_config,\n",
    "                                      sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Step 8: Run the training job by passing the data location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T07:48:53.198317Z",
     "start_time": "2020-04-17T07:48:53.194571Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datascience-model-training-2020-04-17-07-48-53\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "job_prefix_name = 'datascience-model-training'\n",
    "training_job_name = job_prefix_name + '-'  + datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "\n",
    "print(training_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T07:53:55.159763Z",
     "start_time": "2020-04-17T07:48:55.839913Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-17 07:48:56 Starting - Starting the training job...\n",
      "2020-04-17 07:48:58 Starting - Launching requested ML instances...\n",
      "2020-04-17 07:49:56 Starting - Preparing the instances for training......\n",
      "2020-04-17 07:51:01 Downloading - Downloading input data\n",
      "2020-04-17 07:51:01 Training - Downloading the training image............\n",
      "2020-04-17 07:52:54 Training - Training image download completed. Training in progress.\u001b[34m2020-04-17 07:52:55.776323: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6\u001b[0m\n",
      "\u001b[34m2020-04-17 07:52:55.819870: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.6\u001b[0m\n",
      "\u001b[34m2020-04-17 07:52:57.279365: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[34m2020-04-17 07:52:57.314500: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300070000 Hz\u001b[0m\n",
      "\u001b[34m2020-04-17 07:52:57.315560: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4d8f810 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[34m2020-04-17 07:52:57.315584: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[34m2020-04-17 07:52:57.318764: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\u001b[0m\n",
      "\u001b[34m2020-04-17 07:52:57.709131: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2020-04-17 07:52:57.710184: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4db2a00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[34m2020-04-17 07:52:57.710208: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0\u001b[0m\n",
      "\u001b[34m2020-04-17 07:52:57.710424: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2020-04-17 07:52:57.711366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \u001b[0m\n",
      "\u001b[34mpciBusID: 0000:00:1e.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\u001b[0m\n",
      "\u001b[34mcoreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\u001b[0m\n",
      "\u001b[34m2020-04-17 07:52:57.711416: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\u001b[0m\n",
      "\u001b[34m2020-04-17 07:52:57.711468: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\u001b[0m\n",
      "\u001b[34m2020-04-17 07:52:57.753079: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\u001b[0m\n",
      "\u001b[34m2020-04-17 07:52:57.761605: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\u001b[0m\n",
      "\u001b[34m2020-04-17 07:52:57.838852: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\u001b[0m\n",
      "\u001b[34m2020-04-17 07:52:57.848132: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\u001b[0m\n",
      "\u001b[34m2020-04-17 07:52:57.848195: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\u001b[0m\n",
      "\u001b[34m2020-04-17 07:52:57.848304: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2020-04-17 07:52:57.849275: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2020-04-17 07:52:57.850180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\u001b[0m\n",
      "\u001b[34m2020-04-17 07:52:57.850810: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\u001b[0m\n",
      "\u001b[34m2020-04-17 07:52:58.765288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\u001b[0m\n",
      "\u001b[34m2020-04-17 07:52:58.765325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \u001b[0m\n",
      "\u001b[34m2020-04-17 07:52:58.765334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \u001b[0m\n",
      "\u001b[34m2020-04-17 07:52:58.766126: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2020-04-17 07:52:58.767115: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2020-04-17 07:52:58.768023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/device:GPU:0 with 14978 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:1e.0, compute capability: 7.0)\u001b[0m\n",
      "\u001b[34m2020-04-17 07:53:05.562925: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2020-04-17 07:53:05.563906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \u001b[0m\n",
      "\u001b[34mpciBusID: 0000:00:1e.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\u001b[0m\n",
      "\u001b[34mcoreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\u001b[0m\n",
      "\u001b[34m2020-04-17 07:53:05.563949: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\u001b[0m\n",
      "\u001b[34m2020-04-17 07:53:05.563962: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\u001b[0m\n",
      "\u001b[34m2020-04-17 07:53:05.563987: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\u001b[0m\n",
      "\u001b[34m2020-04-17 07:53:05.564008: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\u001b[0m\n",
      "\u001b[34m2020-04-17 07:53:05.564021: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\u001b[0m\n",
      "\u001b[34m2020-04-17 07:53:05.564031: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\u001b[0m\n",
      "\u001b[34m2020-04-17 07:53:05.564040: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\u001b[0m\n",
      "\u001b[34m2020-04-17 07:53:05.564113: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2020-04-17 07:53:05.565094: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2020-04-17 07:53:05.565986: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\u001b[0m\n",
      "\u001b[34m2020-04-17 07:53:05.566479: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2020-04-17 07:53:05.567409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \u001b[0m\n",
      "\u001b[34mpciBusID: 0000:00:1e.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\u001b[0m\n",
      "\u001b[34mcoreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\u001b[0m\n",
      "\u001b[34m2020-04-17 07:53:05.567441: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\u001b[0m\n",
      "\u001b[34m2020-04-17 07:53:05.567451: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\u001b[0m\n",
      "\u001b[34m2020-04-17 07:53:05.567463: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\u001b[0m\n",
      "\u001b[34m2020-04-17 07:53:05.567474: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\u001b[0m\n",
      "\u001b[34m2020-04-17 07:53:05.567485: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\u001b[0m\n",
      "\u001b[34m2020-04-17 07:53:05.567496: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\u001b[0m\n",
      "\u001b[34m2020-04-17 07:53:05.567505: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\u001b[0m\n",
      "\u001b[34m2020-04-17 07:53:05.567558: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2020-04-17 07:53:05.568536: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2020-04-17 07:53:05.569427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\u001b[0m\n",
      "\u001b[34m2020-04-17 07:53:05.569462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\u001b[0m\n",
      "\u001b[34m2020-04-17 07:53:05.569471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \u001b[0m\n",
      "\u001b[34m2020-04-17 07:53:05.569477: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \u001b[0m\n",
      "\u001b[34m2020-04-17 07:53:05.569573: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2020-04-17 07:53:05.570591: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2020-04-17 07:53:05.571489: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14978 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:1e.0, compute capability: 7.0)\u001b[0m\n",
      "\u001b[34m2020-04-17 07:53:08.047898: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\u001b[0m\n",
      "\u001b[34m[name: \"/device:CPU:0\"\u001b[0m\n",
      "\u001b[34mdevice_type: \"CPU\"\u001b[0m\n",
      "\u001b[34mmemory_limit: 268435456\u001b[0m\n",
      "\u001b[34mlocality {\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mincarnation: 11125628105407352693\u001b[0m\n",
      "\u001b[34m, name: \"/device:XLA_CPU:0\"\u001b[0m\n",
      "\u001b[34mdevice_type: \"XLA_CPU\"\u001b[0m\n",
      "\u001b[34mmemory_limit: 17179869184\u001b[0m\n",
      "\u001b[34mlocality {\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mincarnation: 7147136703836645054\u001b[0m\n",
      "\u001b[34mphysical_device_desc: \"device: XLA_CPU device\"\u001b[0m\n",
      "\u001b[34m, name: \"/device:XLA_GPU:0\"\u001b[0m\n",
      "\u001b[34mdevice_type: \"XLA_GPU\"\u001b[0m\n",
      "\u001b[34mmemory_limit: 17179869184\u001b[0m\n",
      "\u001b[34mlocality {\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mincarnation: 7514113534192553707\u001b[0m\n",
      "\u001b[34mphysical_device_desc: \"device: XLA_GPU device\"\u001b[0m\n",
      "\u001b[34m, name: \"/device:GPU:0\"\u001b[0m\n",
      "\u001b[34mdevice_type: \"GPU\"\u001b[0m\n",
      "\u001b[34mmemory_limit: 15705692570\u001b[0m\n",
      "\u001b[34mlocality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mincarnation: 4429478978375218070\u001b[0m\n",
      "\u001b[34mphysical_device_desc: \"device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:1e.0, compute capability: 7.0\"\u001b[0m\n",
      "\u001b[34m]\n",
      "\u001b[0m\n",
      "\u001b[34mScript Status - Starting\n",
      "\u001b[0m\n",
      "\u001b[34mReading hyper parameters\u001b[0m\n",
      "\u001b[34mFinished reading the hyper parameters.\n",
      "\u001b[0m\n",
      "\u001b[34mReading the data.\n",
      "\u001b[0m\n",
      "\u001b[34mNumber of data samples:  10000\u001b[0m\n",
      "\u001b[34mNumber of data labels:  10000\n",
      "\u001b[0m\n",
      "\u001b[34mNumber of training samples:  ((8000, 784), (8000, 10))\u001b[0m\n",
      "\u001b[34mNumber of test samples:  ((2000, 784), (2000, 10))\u001b[0m\n",
      "\u001b[34mFinished data reading and pre-processing.\n",
      "\u001b[0m\n",
      "\u001b[34mStarting the model training\u001b[0m\n",
      "\u001b[34mModel: \"sequential_1\"\u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mLayer (type)                 Output Shape              Param #   \u001b[0m\n",
      "\u001b[34m=================================================================\u001b[0m\n",
      "\u001b[34mdense_1 (Dense)              (None, 512)               401920    \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mdropout_1 (Dropout)          (None, 512)               0         \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mdense_2 (Dense)              (None, 512)               262656    \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mdropout_2 (Dropout)          (None, 512)               0         \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mdense_3 (Dense)              (None, 10)                5130      \u001b[0m\n",
      "\u001b[34m=================================================================\u001b[0m\n",
      "\u001b[34mTotal params: 669,706\u001b[0m\n",
      "\u001b[34mTrainable params: 669,706\u001b[0m\n",
      "\u001b[34mNon-trainable params: 0\u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mTrain on 8000 samples, validate on 2000 samples\u001b[0m\n",
      "\u001b[34mEpoch 1/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 52s - loss: 2.3026 - accuracy: 0.1328\u001b[0m\n",
      "\u001b[34m2560/8000 [========>.....................] - ETA: 1s - loss: 2.2499 - accuracy: 0.2387 \u001b[0m\n",
      "\u001b[34m4992/8000 [=================>............] - ETA: 0s - loss: 2.1337 - accuracy: 0.3395\u001b[0m\n",
      "\u001b[34m7424/8000 [==========================>...] - ETA: 0s - loss: 1.9754 - accuracy: 0.4069\u001b[0m\n",
      "\u001b[34m8000/8000 [==============================] - 1s 137us/step - loss: 1.9359 - accuracy: 0.4221 - val_loss: 1.3310 - val_accuracy: 0.6090\u001b[0m\n",
      "\u001b[34mEpoch 2/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 1.4262 - accuracy: 0.5938\u001b[0m\n",
      "\u001b[34m2560/8000 [========>.....................] - ETA: 0s - loss: 1.2743 - accuracy: 0.6141\u001b[0m\n",
      "\u001b[34m5120/8000 [==================>...........] - ETA: 0s - loss: 1.1778 - accuracy: 0.6355\u001b[0m\n",
      "\u001b[34m7552/8000 [===========================>..] - ETA: 0s - loss: 1.1152 - accuracy: 0.6515\u001b[0m\n",
      "\u001b[34m8000/8000 [==============================] - 0s 25us/step - loss: 1.1017 - accuracy: 0.6553 - val_loss: 0.7886 - val_accuracy: 0.8120\u001b[0m\n",
      "\u001b[34mEpoch 3/30\n",
      "\u001b[0m\n",
      "\u001b[34m 128/8000 [..............................] - ETA: 0s - loss: 0.9783 - accuracy: 0.7656\u001b[0m\n",
      "\u001b[34m2560/8000 [========>.....................] - ETA: 0s - loss: 0.8611 - accuracy: 0.7285\u001b[0m\n",
      "\u001b[34m4992/8000 [=================>............] - ETA: 0s - loss: 0.8413 - accuracy: 0.7372\u001b[0m\n",
      "\u001b[34m7552/8000 [===========================>..] - ETA: 0s - loss: 0.8116 - accuracy: 0.7467\u001b[0m\n",
      "\u001b[34m8000/8000 [==============================] - 0s 25us/step - loss: 0.8065 - accuracy: 0.7480 - val_loss: 0.6088 - val_accuracy: 0.8200\u001b[0m\n",
      "\u001b[34mEpoch 4/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.7251 - accuracy: 0.7578\u001b[0m\n",
      "\u001b[34m2560/8000 [========>.....................] - ETA: 0s - loss: 0.7080 - accuracy: 0.7797\u001b[0m\n",
      "\u001b[34m4992/8000 [=================>............] - ETA: 0s - loss: 0.6712 - accuracy: 0.7967\u001b[0m\n",
      "\u001b[34m7296/8000 [==========================>...] - ETA: 0s - loss: 0.6687 - accuracy: 0.7941\u001b[0m\n",
      "\u001b[34m8000/8000 [==============================] - 0s 26us/step - loss: 0.6634 - accuracy: 0.7962 - val_loss: 0.4936 - val_accuracy: 0.8710\u001b[0m\n",
      "\u001b[34mEpoch 5/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.5924 - accuracy: 0.8047\u001b[0m\n",
      "\u001b[34m2688/8000 [=========>....................] - ETA: 0s - loss: 0.5955 - accuracy: 0.8151\u001b[0m\n",
      "\u001b[34m5120/8000 [==================>...........] - ETA: 0s - loss: 0.5817 - accuracy: 0.8199\u001b[0m\n",
      "\u001b[34m7552/8000 [===========================>..] - ETA: 0s - loss: 0.5642 - accuracy: 0.8279\u001b[0m\n",
      "\u001b[34m8000/8000 [==============================] - 0s 24us/step - loss: 0.5655 - accuracy: 0.8266 - val_loss: 0.4382 - val_accuracy: 0.8695\u001b[0m\n",
      "\u001b[34mEpoch 6/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.6382 - accuracy: 0.7891\u001b[0m\n",
      "\u001b[34m2560/8000 [========>.....................] - ETA: 0s - loss: 0.5185 - accuracy: 0.8363\u001b[0m\n",
      "\u001b[34m4992/8000 [=================>............] - ETA: 0s - loss: 0.5195 - accuracy: 0.8365\u001b[0m\n",
      "\u001b[34m7296/8000 [==========================>...] - ETA: 0s - loss: 0.5033 - accuracy: 0.8416\u001b[0m\n",
      "\u001b[34m8000/8000 [==============================] - 0s 25us/step - loss: 0.5002 - accuracy: 0.8419 - val_loss: 0.3689 - val_accuracy: 0.8995\u001b[0m\n",
      "\u001b[34mEpoch 7/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.4659 - accuracy: 0.8359\u001b[0m\n",
      "\u001b[34m2560/8000 [========>.....................] - ETA: 0s - loss: 0.4766 - accuracy: 0.8523\u001b[0m\n",
      "\u001b[34m5120/8000 [==================>...........] - ETA: 0s - loss: 0.4655 - accuracy: 0.8551\u001b[0m\n",
      "\u001b[34m7680/8000 [===========================>..] - ETA: 0s - loss: 0.4515 - accuracy: 0.8600\u001b[0m\n",
      "\u001b[34m8000/8000 [==============================] - 0s 24us/step - loss: 0.4502 - accuracy: 0.8609 - val_loss: 0.3319 - val_accuracy: 0.9050\u001b[0m\n",
      "\u001b[34mEpoch 8/30\n",
      "\u001b[0m\n",
      "\u001b[34m 128/8000 [..............................] - ETA: 0s - loss: 0.4190 - accuracy: 0.8438\u001b[0m\n",
      "\u001b[34m2560/8000 [========>.....................] - ETA: 0s - loss: 0.4294 - accuracy: 0.8629\u001b[0m\n",
      "\u001b[34m4992/8000 [=================>............] - ETA: 0s - loss: 0.4225 - accuracy: 0.8690\u001b[0m\n",
      "\u001b[34m7424/8000 [==========================>...] - ETA: 0s - loss: 0.4150 - accuracy: 0.8716\u001b[0m\n",
      "\u001b[34m8000/8000 [==============================] - 0s 25us/step - loss: 0.4108 - accuracy: 0.8725 - val_loss: 0.2880 - val_accuracy: 0.9225\u001b[0m\n",
      "\u001b[34mEpoch 9/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.4830 - accuracy: 0.8438\u001b[0m\n",
      "\u001b[34m2560/8000 [========>.....................] - ETA: 0s - loss: 0.3909 - accuracy: 0.8863\u001b[0m\n",
      "\u001b[34m4992/8000 [=================>............] - ETA: 0s - loss: 0.3847 - accuracy: 0.8840\u001b[0m\n",
      "\u001b[34m7552/8000 [===========================>..] - ETA: 0s - loss: 0.3813 - accuracy: 0.8841\u001b[0m\n",
      "\u001b[34m8000/8000 [==============================] - 0s 25us/step - loss: 0.3801 - accuracy: 0.8841 - val_loss: 0.2696 - val_accuracy: 0.9245\u001b[0m\n",
      "\u001b[34mEpoch 10/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.4365 - accuracy: 0.8516\u001b[0m\n",
      "\u001b[34m2560/8000 [========>.....................] - ETA: 0s - loss: 0.3762 - accuracy: 0.8824\u001b[0m\n",
      "\u001b[34m4992/8000 [=================>............] - ETA: 0s - loss: 0.3651 - accuracy: 0.8888\u001b[0m\n",
      "\u001b[34m7424/8000 [==========================>...] - ETA: 0s - loss: 0.3615 - accuracy: 0.8886\u001b[0m\n",
      "\u001b[34m8000/8000 [==============================] - 0s 25us/step - loss: 0.3634 - accuracy: 0.8884 - val_loss: 0.2637 - val_accuracy: 0.9260\u001b[0m\n",
      "\u001b[34mEpoch 11/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.2961 - accuracy: 0.9219\u001b[0m\n",
      "\u001b[34m2688/8000 [=========>....................] - ETA: 0s - loss: 0.3538 - accuracy: 0.8917\u001b[0m\n",
      "\u001b[34m5248/8000 [==================>...........] - ETA: 0s - loss: 0.3523 - accuracy: 0.8901\u001b[0m\n",
      "\u001b[34m7680/8000 [===========================>..] - ETA: 0s - loss: 0.3392 - accuracy: 0.8932\u001b[0m\n",
      "\u001b[34m8000/8000 [==============================] - 0s 25us/step - loss: 0.3380 - accuracy: 0.8940 - val_loss: 0.2522 - val_accuracy: 0.9285\u001b[0m\n",
      "\u001b[34mEpoch 12/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.3205 - accuracy: 0.9062\u001b[0m\n",
      "\u001b[34m2432/8000 [========>.....................] - ETA: 0s - loss: 0.3519 - accuracy: 0.8910\u001b[0m\n",
      "\u001b[34m4864/8000 [=================>............] - ETA: 0s - loss: 0.3375 - accuracy: 0.8947\u001b[0m\n",
      "\u001b[34m7296/8000 [==========================>...] - ETA: 0s - loss: 0.3276 - accuracy: 0.9009\u001b[0m\n",
      "\u001b[34m8000/8000 [==============================] - 0s 25us/step - loss: 0.3230 - accuracy: 0.9024 - val_loss: 0.2583 - val_accuracy: 0.9260\u001b[0m\n",
      "\u001b[34mEpoch 13/30\n",
      "\u001b[0m\n",
      "\u001b[34m 128/8000 [..............................] - ETA: 0s - loss: 0.2833 - accuracy: 0.9141\u001b[0m\n",
      "\u001b[34m2560/8000 [========>.....................] - ETA: 0s - loss: 0.3071 - accuracy: 0.9078\u001b[0m\n",
      "\u001b[34m5120/8000 [==================>...........] - ETA: 0s - loss: 0.3038 - accuracy: 0.9070\u001b[0m\n",
      "\u001b[34m7552/8000 [===========================>..] - ETA: 0s - loss: 0.3052 - accuracy: 0.9053\u001b[0m\n",
      "\u001b[34m8000/8000 [==============================] - 0s 25us/step - loss: 0.3047 - accuracy: 0.9051 - val_loss: 0.2388 - val_accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mEpoch 14/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.2366 - accuracy: 0.9297\u001b[0m\n",
      "\u001b[34m2560/8000 [========>.....................] - ETA: 0s - loss: 0.3027 - accuracy: 0.9090\u001b[0m\n",
      "\u001b[34m4992/8000 [=================>............] - ETA: 0s - loss: 0.2945 - accuracy: 0.9111\u001b[0m\n",
      "\u001b[34m7424/8000 [==========================>...] - ETA: 0s - loss: 0.2953 - accuracy: 0.9103\u001b[0m\n",
      "\u001b[34m8000/8000 [==============================] - 0s 25us/step - loss: 0.2932 - accuracy: 0.9111 - val_loss: 0.2327 - val_accuracy: 0.9320\u001b[0m\n",
      "\u001b[34mEpoch 15/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.2701 - accuracy: 0.8906\u001b[0m\n",
      "\u001b[34m2560/8000 [========>.....................] - ETA: 0s - loss: 0.2661 - accuracy: 0.9199\u001b[0m\n",
      "\u001b[34m4992/8000 [=================>............] - ETA: 0s - loss: 0.2677 - accuracy: 0.9171\u001b[0m\n",
      "\u001b[34m7552/8000 [===========================>..] - ETA: 0s - loss: 0.2775 - accuracy: 0.9159\u001b[0m\n",
      "\u001b[34m8000/8000 [==============================] - 0s 25us/step - loss: 0.2771 - accuracy: 0.9161 - val_loss: 0.2239 - val_accuracy: 0.9365\u001b[0m\n",
      "\u001b[34mEpoch 16/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.2674 - accuracy: 0.9297\u001b[0m\n",
      "\u001b[34m2560/8000 [========>.....................] - ETA: 0s - loss: 0.2590 - accuracy: 0.9270\u001b[0m\n",
      "\u001b[34m5120/8000 [==================>...........] - ETA: 0s - loss: 0.2562 - accuracy: 0.9250\u001b[0m\n",
      "\u001b[34m7552/8000 [===========================>..] - ETA: 0s - loss: 0.2653 - accuracy: 0.9204\u001b[0m\n",
      "\u001b[34m8000/8000 [==============================] - 0s 25us/step - loss: 0.2654 - accuracy: 0.9200 - val_loss: 0.2202 - val_accuracy: 0.9405\u001b[0m\n",
      "\u001b[34mEpoch 17/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.2562 - accuracy: 0.9141\u001b[0m\n",
      "\u001b[34m2688/8000 [=========>....................] - ETA: 0s - loss: 0.2697 - accuracy: 0.9200\u001b[0m\n",
      "\u001b[34m5248/8000 [==================>...........] - ETA: 0s - loss: 0.2592 - accuracy: 0.9219\u001b[0m\n",
      "\u001b[34m7680/8000 [===========================>..] - ETA: 0s - loss: 0.2562 - accuracy: 0.9228\u001b[0m\n",
      "\u001b[34m8000/8000 [==============================] - 0s 24us/step - loss: 0.2547 - accuracy: 0.9227 - val_loss: 0.2110 - val_accuracy: 0.9365\u001b[0m\n",
      "\u001b[34mEpoch 18/30\n",
      "\u001b[0m\n",
      "\u001b[34m 128/8000 [..............................] - ETA: 0s - loss: 0.3219 - accuracy: 0.8906\u001b[0m\n",
      "\u001b[34m2560/8000 [========>.....................] - ETA: 0s - loss: 0.2369 - accuracy: 0.9230\u001b[0m\n",
      "\u001b[34m4992/8000 [=================>............] - ETA: 0s - loss: 0.2414 - accuracy: 0.9245\u001b[0m\n",
      "\u001b[34m7424/8000 [==========================>...] - ETA: 0s - loss: 0.2434 - accuracy: 0.9230\u001b[0m\n",
      "\u001b[34m8000/8000 [==============================] - 0s 25us/step - loss: 0.2467 - accuracy: 0.9224 - val_loss: 0.1905 - val_accuracy: 0.9455\u001b[0m\n",
      "\u001b[34mEpoch 19/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.2436 - accuracy: 0.9219\u001b[0m\n",
      "\u001b[34m2560/8000 [========>.....................] - ETA: 0s - loss: 0.2184 - accuracy: 0.9359\u001b[0m\n",
      "\u001b[34m4992/8000 [=================>............] - ETA: 0s - loss: 0.2299 - accuracy: 0.9319\u001b[0m\n",
      "\u001b[34m7424/8000 [==========================>...] - ETA: 0s - loss: 0.2340 - accuracy: 0.9298\u001b[0m\n",
      "\u001b[34m8000/8000 [==============================] - 0s 25us/step - loss: 0.2337 - accuracy: 0.9291 - val_loss: 0.1888 - val_accuracy: 0.9450\u001b[0m\n",
      "\u001b[34mEpoch 20/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.2140 - accuracy: 0.9297\u001b[0m\n",
      "\u001b[34m2560/8000 [========>.....................] - ETA: 0s - loss: 0.2402 - accuracy: 0.9262\u001b[0m\n",
      "\u001b[34m5120/8000 [==================>...........] - ETA: 0s - loss: 0.2271 - accuracy: 0.9281\u001b[0m\n",
      "\u001b[34m7424/8000 [==========================>...] - ETA: 0s - loss: 0.2297 - accuracy: 0.9278\u001b[0m\n",
      "\u001b[34m8000/8000 [==============================] - 0s 25us/step - loss: 0.2242 - accuracy: 0.9296 - val_loss: 0.1922 - val_accuracy: 0.9450\u001b[0m\n",
      "\u001b[34mEpoch 21/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.2362 - accuracy: 0.9531\u001b[0m\n",
      "\u001b[34m2560/8000 [========>.....................] - ETA: 0s - loss: 0.2208 - accuracy: 0.9316\u001b[0m\n",
      "\u001b[34m5120/8000 [==================>...........] - ETA: 0s - loss: 0.2206 - accuracy: 0.9316\u001b[0m\n",
      "\u001b[34m7552/8000 [===========================>..] - ETA: 0s - loss: 0.2154 - accuracy: 0.9345\u001b[0m\n",
      "\u001b[34m8000/8000 [==============================] - 0s 25us/step - loss: 0.2135 - accuracy: 0.9346 - val_loss: 0.1904 - val_accuracy: 0.9460\u001b[0m\n",
      "\u001b[34mEpoch 22/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.1971 - accuracy: 0.9297\u001b[0m\n",
      "\u001b[34m2560/8000 [========>.....................] - ETA: 0s - loss: 0.1960 - accuracy: 0.9422\u001b[0m\n",
      "\u001b[34m5120/8000 [==================>...........] - ETA: 0s - loss: 0.2101 - accuracy: 0.9377\u001b[0m\n",
      "\u001b[34m7552/8000 [===========================>..] - ETA: 0s - loss: 0.2053 - accuracy: 0.9380\u001b[0m\n",
      "\u001b[34m8000/8000 [==============================] - 0s 24us/step - loss: 0.2051 - accuracy: 0.9380 - val_loss: 0.1792 - val_accuracy: 0.9465\u001b[0m\n",
      "\u001b[34mEpoch 23/30\n",
      "\u001b[0m\n",
      "\u001b[34m 128/8000 [..............................] - ETA: 0s - loss: 0.1667 - accuracy: 0.9297\u001b[0m\n",
      "\u001b[34m2560/8000 [========>.....................] - ETA: 0s - loss: 0.1906 - accuracy: 0.9387\u001b[0m\n",
      "\u001b[34m5120/8000 [==================>...........] - ETA: 0s - loss: 0.1947 - accuracy: 0.9400\u001b[0m\n",
      "\u001b[34m7552/8000 [===========================>..] - ETA: 0s - loss: 0.2012 - accuracy: 0.9375\u001b[0m\n",
      "\u001b[34m8000/8000 [==============================] - 0s 24us/step - loss: 0.1992 - accuracy: 0.9377 - val_loss: 0.1741 - val_accuracy: 0.9485\u001b[0m\n",
      "\u001b[34mEpoch 24/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.1341 - accuracy: 0.9531\u001b[0m\n",
      "\u001b[34m2560/8000 [========>.....................] - ETA: 0s - loss: 0.1820 - accuracy: 0.9445\u001b[0m\n",
      "\u001b[34m4992/8000 [=================>............] - ETA: 0s - loss: 0.1884 - accuracy: 0.9433\u001b[0m\n",
      "\u001b[34m7424/8000 [==========================>...] - ETA: 0s - loss: 0.1936 - accuracy: 0.9403\u001b[0m\n",
      "\u001b[34m8000/8000 [==============================] - 0s 25us/step - loss: 0.1913 - accuracy: 0.9408 - val_loss: 0.1704 - val_accuracy: 0.9505\u001b[0m\n",
      "\u001b[34mEpoch 25/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.2111 - accuracy: 0.9531\u001b[0m\n",
      "\u001b[34m2688/8000 [=========>....................] - ETA: 0s - loss: 0.1756 - accuracy: 0.9468\u001b[0m\n",
      "\u001b[34m5120/8000 [==================>...........] - ETA: 0s - loss: 0.1769 - accuracy: 0.9498\u001b[0m\n",
      "\u001b[34m7552/8000 [===========================>..] - ETA: 0s - loss: 0.1791 - accuracy: 0.9461\u001b[0m\n",
      "\u001b[34m8000/8000 [==============================] - 0s 24us/step - loss: 0.1783 - accuracy: 0.9460 - val_loss: 0.1927 - val_accuracy: 0.9440\u001b[0m\n",
      "\u001b[34mEpoch 26/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.2240 - accuracy: 0.9297\u001b[0m\n",
      "\u001b[34m2560/8000 [========>.....................] - ETA: 0s - loss: 0.1731 - accuracy: 0.9527\u001b[0m\n",
      "\u001b[34m5120/8000 [==================>...........] - ETA: 0s - loss: 0.1738 - accuracy: 0.9480\u001b[0m\n",
      "\u001b[34m7552/8000 [===========================>..] - ETA: 0s - loss: 0.1739 - accuracy: 0.9462\u001b[0m\n",
      "\u001b[34m8000/8000 [==============================] - 0s 25us/step - loss: 0.1717 - accuracy: 0.9464 - val_loss: 0.1647 - val_accuracy: 0.9520\u001b[0m\n",
      "\u001b[34mEpoch 27/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.1458 - accuracy: 0.9609\u001b[0m\n",
      "\u001b[34m2560/8000 [========>.....................] - ETA: 0s - loss: 0.1784 - accuracy: 0.9410\u001b[0m\n",
      "\u001b[34m5120/8000 [==================>...........] - ETA: 0s - loss: 0.1639 - accuracy: 0.9488\u001b[0m\n",
      "\u001b[34m7552/8000 [===========================>..] - ETA: 0s - loss: 0.1605 - accuracy: 0.9488\u001b[0m\n",
      "\u001b[34m8000/8000 [==============================] - 0s 25us/step - loss: 0.1643 - accuracy: 0.9479 - val_loss: 0.1612 - val_accuracy: 0.9515\u001b[0m\n",
      "\u001b[34mEpoch 28/30\n",
      "\u001b[0m\n",
      "\u001b[34m 128/8000 [..............................] - ETA: 0s - loss: 0.1771 - accuracy: 0.9375\u001b[0m\n",
      "\u001b[34m2560/8000 [========>.....................] - ETA: 0s - loss: 0.1654 - accuracy: 0.9539\u001b[0m\n",
      "\u001b[34m4992/8000 [=================>............] - ETA: 0s - loss: 0.1550 - accuracy: 0.9525\u001b[0m\n",
      "\u001b[34m7424/8000 [==========================>...] - ETA: 0s - loss: 0.1538 - accuracy: 0.9527\u001b[0m\n",
      "\u001b[34m8000/8000 [==============================] - 0s 25us/step - loss: 0.1538 - accuracy: 0.9529 - val_loss: 0.1560 - val_accuracy: 0.9565\u001b[0m\n",
      "\u001b[34mEpoch 29/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.1421 - accuracy: 0.9609\u001b[0m\n",
      "\u001b[34m2688/8000 [=========>....................] - ETA: 0s - loss: 0.1609 - accuracy: 0.9513\u001b[0m\n",
      "\u001b[34m5248/8000 [==================>...........] - ETA: 0s - loss: 0.1556 - accuracy: 0.9524\u001b[0m\n",
      "\u001b[34m7808/8000 [============================>.] - ETA: 0s - loss: 0.1532 - accuracy: 0.9526\u001b[0m\n",
      "\u001b[34m8000/8000 [==============================] - 0s 24us/step - loss: 0.1537 - accuracy: 0.9528 - val_loss: 0.1560 - val_accuracy: 0.9590\u001b[0m\n",
      "\u001b[34mEpoch 30/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.1412 - accuracy: 0.9375\u001b[0m\n",
      "\u001b[34m2176/8000 [=======>......................] - ETA: 0s - loss: 0.1443 - accuracy: 0.9568\u001b[0m\n",
      "\u001b[34m4608/8000 [================>.............] - ETA: 0s - loss: 0.1438 - accuracy: 0.9581\u001b[0m\n",
      "\u001b[34m7040/8000 [=========================>....] - ETA: 0s - loss: 0.1423 - accuracy: 0.9574\u001b[0m\n",
      "\u001b[34m8000/8000 [==============================] - 0s 26us/step - loss: 0.1427 - accuracy: 0.9571 - val_loss: 0.1477 - val_accuracy: 0.9575\n",
      "\u001b[0m\n",
      "\u001b[34mFinished training the model.\u001b[0m\n",
      "\u001b[34mUsing TensorFlow backend.\u001b[0m\n",
      "\u001b[34mTest loss: 0.1477157659046352\u001b[0m\n",
      "\u001b[34mTest accuracy: 0.9574999809265137\n",
      "\u001b[0m\n",
      "\u001b[34mSaving the model.\u001b[0m\n",
      "\u001b[34mFinished saving the model.\u001b[0m\n",
      "\u001b[34mFinished training the model.\n",
      "\u001b[0m\n",
      "\u001b[34mScript Status - Finished\n",
      "\u001b[0m\n",
      "\u001b[34mTotal time taken:  17.573973417282104\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-04-17 07:53:25 Uploading - Uploading generated training model\n",
      "2020-04-17 07:53:25 Completed - Training job completed\n",
      "Training seconds: 160\n",
      "Billable seconds: 160\n"
     ]
    }
   ],
   "source": [
    "classifier.fit(inputs=data_location, \n",
    "              logs=True, \n",
    "              job_name=training_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! We had a successful training job run in Amazon SageMaker.\n",
    "#### Please return to the tutorial for Part 6 where we will be running a training job in a GPU."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-keras-mlflow-sagemaker",
   "language": "python",
   "name": "tensorflow-keras-mlflow-sagemaker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
